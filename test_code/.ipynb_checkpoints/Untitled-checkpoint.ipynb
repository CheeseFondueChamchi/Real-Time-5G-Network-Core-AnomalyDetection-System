{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766c25c2-d34d-42d0-9a96-ec59fc82877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -0.81818182 -0.63636364 -0.45454545]\n",
      " [-0.81818182 -0.63636364 -0.45454545 -0.27272727]\n",
      " [-0.63636364 -0.45454545 -0.27272727 -0.09090909]\n",
      " [-0.45454545 -0.27272727 -0.09090909  0.09090909]\n",
      " [-0.27272727 -0.09090909  0.09090909  0.27272727]\n",
      " [-0.09090909  0.09090909  0.27272727  0.45454545]\n",
      " [ 0.09090909  0.27272727  0.45454545  0.63636364]\n",
      " [ 0.27272727  0.45454545  0.63636364  0.81818182]\n",
      " [ 0.45454545  0.63636364  0.81818182  1.        ]]\n",
      "[-2.90909091 -2.18181818 -1.45454545 -0.72727273  0.          0.72727273\n",
      "  1.45454545  2.18181818  2.90909091]\n",
      "     A   B  A_partially_scaled\n",
      "0    1   2           -2.909091\n",
      "1    2   4           -2.181818\n",
      "2    3   6           -1.454545\n",
      "3    4   8           -0.727273\n",
      "4    5  10            0.000000\n",
      "5    6  12            0.000000\n",
      "6    7  14            0.000000\n",
      "7    8  16            0.000000\n",
      "8    9  18            0.000000\n",
      "9   10  20            0.000000\n",
      "10  11  22            0.000000\n",
      "11  12  24            0.000000\n",
      "0   -2.909091\n",
      "1   -2.181818\n",
      "2   -1.454545\n",
      "3   -0.727273\n",
      "Name: A_partially_scaled, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     45\u001b[0m processor \u001b[38;5;241m=\u001b[39m DataProcessor(df)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPartialScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(processor\u001b[38;5;241m.\u001b[39mdf)\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36mDataProcessor.PartialScaler\u001b[0;34m(self, col, seq_len, scaler_type, path, save)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[:seq_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, col_scaled])\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[seq_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:, col_scaled] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(window_data_sum)[seq_len\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mto_csv(path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/torch/lib/python3.9/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/torch/lib/python3.9/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/mambaforge/envs/torch/lib/python3.9/site-packages/pandas/core/indexing.py:1850\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;66;03m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;66;03m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[38;5;241m0\u001b[39m]), value[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1851\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1852\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen setting with an iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex):\n\u001b[1;32m   1856\u001b[0m     \u001b[38;5;66;03m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def PartialScaler(self, col, seq_len=8, scaler_type=\"Robust\", path=\"./\", save=False):\n",
    "        scaler_dict = {\n",
    "            \"Robust\": RobustScaler(),\n",
    "            \"Standard\": StandardScaler(),\n",
    "            \"MinMax\": MinMaxScaler()\n",
    "        }\n",
    "        \n",
    "        scaler = scaler_dict[scaler_type]\n",
    "        col_scaled = f'{col}_partially_scaled'\n",
    "        \n",
    "        self.df[col_scaled] = 0\n",
    "        \n",
    "        data = self.df[col].values.reshape(-1, 1)\n",
    "        scaled_data = scaler.fit_transform(data)\n",
    "        scaled_data = scaled_data.reshape(-1)\n",
    "        \n",
    "        window_data = np.lib.stride_tricks.sliding_window_view(scaled_data, window_shap3e=(seq_len,))\n",
    "        print(window_data)\n",
    "        window_data_sum = np.sum(window_data, axis=1)\n",
    "        print(window_data_sum)\n",
    "        self.df.loc[:seq_len-1, col_scaled] = window_data_sum[:seq_len]\n",
    "        print(self.df)\n",
    "        print(self.df.loc[:seq_len-1, col_scaled])\n",
    "        self.df.loc[seq_len-1:, col_scaled] = np.cumsum(window_data_sum)[seq_len-1:]\n",
    "        \n",
    "        if save:\n",
    "            self.df.to_csv(path, index=False)\n",
    "\n",
    "            \n",
    "# Example usage\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'B': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "processor = DataProcessor(df)\n",
    "processor.PartialScaler('A', seq_len=4)\n",
    "print(processor.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "31438529-2824-42e1-aa45-f90949ee3b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      4\n",
      "2      6\n",
      "3      8\n",
      "4     10\n",
      "5     12\n",
      "6     14\n",
      "7     16\n",
      "8     18\n",
      "9     20\n",
      "10    22\n",
      "11    24\n",
      "Name: B, dtype: int64\n",
      "[[ 2  4  6  8]\n",
      " [ 4  6  8 10]\n",
      " [ 6  8 10 12]\n",
      " [ 8 10 12 14]\n",
      " [10 12 14 16]\n",
      " [12 14 16 18]\n",
      " [14 16 18 20]\n",
      " [16 18 20 22]\n",
      " [18 20 22 24]]\n",
      "(9, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_sub_seqs(x_arr, seq_len=100, stride=1,partial_scaling = False):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_arr: np.array, required\n",
    "        input original data with shape [time_length, channels]\n",
    "\n",
    "    seq_len: int, optional (default=100)\n",
    "        Size of window used to create subsequences from the data\n",
    "\n",
    "    stride: int, optional (default=1)\n",
    "        number of time points the window will move between two subsequences\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_seqs: np.array\n",
    "        Split sub-sequences of input time-series data\n",
    "    \"\"\"\n",
    "\n",
    "    seq_starts = np.arange(0, x_arr.shape[0] - seq_len + 1, stride)\n",
    "    x_seqs = np.array([x_arr[i:i + seq_len] for i in seq_starts])\n",
    "    if partial_scaling == True:\n",
    "        \n",
    "        num_cols = 0 # 배열의 열(column) 개수\n",
    "        x_ori = x_seqs[:,:,-1] # 0 feature 내 0번째 축\n",
    "\n",
    "        x_ori_2 = x_seqs[:,:,-1][:,:seq_len-1] # 0 feature 내 0번째 축\n",
    "        # 추가할 열(column)의 개수\n",
    "        num_additional_cols = 1\n",
    "\n",
    "        mean = np.mean(x_ori_2,axis=1) # 평균 계산\n",
    "        std = np.std(x_ori_2,axis=1) # 표준 편차 계산\n",
    "        x_scaled = (x_ori - mean[:, np.newaxis]) / std[:, np.newaxis]\n",
    "        x_scaled = np.reshape(x_scaled,(-1,seq_len,1))\n",
    "        x_seqs = np.concatenate((x_seqs, x_scaled), axis=-1)\n",
    "\n",
    "\n",
    "    return x_seqs\n",
    "# Example usage\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    'B': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "arrat=get_sub_seqs(df, seq_len=4,partial_scaling = True)\n",
    "print(arrat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "570d10e7-daf5-4c69-b836-1d92c7cd42e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.        ,  2.        , -1.22474487],\n",
       "        [ 2.        ,  4.        ,  0.        ],\n",
       "        [ 3.        ,  6.        ,  1.22474487],\n",
       "        [ 4.        ,  8.        ,  2.44948974]],\n",
       "\n",
       "       [[ 2.        ,  4.        , -1.22474487],\n",
       "        [ 3.        ,  6.        ,  0.        ],\n",
       "        [ 4.        ,  8.        ,  1.22474487],\n",
       "        [ 5.        , 10.        ,  2.44948974]],\n",
       "\n",
       "       [[ 3.        ,  6.        , -1.22474487],\n",
       "        [ 4.        ,  8.        ,  0.        ],\n",
       "        [ 5.        , 10.        ,  1.22474487],\n",
       "        [ 6.        , 12.        ,  2.44948974]],\n",
       "\n",
       "       [[ 4.        ,  8.        , -1.22474487],\n",
       "        [ 5.        , 10.        ,  0.        ],\n",
       "        [ 6.        , 12.        ,  1.22474487],\n",
       "        [ 7.        , 14.        ,  2.44948974]],\n",
       "\n",
       "       [[ 5.        , 10.        , -1.22474487],\n",
       "        [ 6.        , 12.        ,  0.        ],\n",
       "        [ 7.        , 14.        ,  1.22474487],\n",
       "        [ 8.        , 16.        ,  2.44948974]],\n",
       "\n",
       "       [[ 6.        , 12.        , -1.22474487],\n",
       "        [ 7.        , 14.        ,  0.        ],\n",
       "        [ 8.        , 16.        ,  1.22474487],\n",
       "        [ 9.        , 18.        ,  2.44948974]],\n",
       "\n",
       "       [[ 7.        , 14.        , -1.22474487],\n",
       "        [ 8.        , 16.        ,  0.        ],\n",
       "        [ 9.        , 18.        ,  1.22474487],\n",
       "        [10.        , 20.        ,  2.44948974]],\n",
       "\n",
       "       [[ 8.        , 16.        , -1.22474487],\n",
       "        [ 9.        , 18.        ,  0.        ],\n",
       "        [10.        , 20.        ,  1.22474487],\n",
       "        [11.        , 22.        ,  2.44948974]],\n",
       "\n",
       "       [[ 9.        , 18.        , -1.22474487],\n",
       "        [10.        , 20.        ,  0.        ],\n",
       "        [11.        , 22.        ,  1.22474487],\n",
       "        [12.        , 24.        ,  2.44948974]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f148cac-c41c-4fb6-b37d-51f8c1a17dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrat[:,:,0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bba8c43-196e-4b45-b164-f25641c56fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
